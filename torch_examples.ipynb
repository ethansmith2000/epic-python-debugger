{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from debugger import epic_debugger, epic_debugger_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_always: will run the normal_debug_fn even if there is no exception\n",
    "# enabled: will completely enable/disable the debugger, useful if you have some kind of global toggle\n",
    "# do_pdb: activate python debugger after printing error and trace\n",
    "\n",
    "# exception_fn: function to run when an exception is caught\n",
    "# normal_debug_fn: function to run when no exception is caught\n",
    "\n",
    "# for these two functions, any additional kwargs you provide will be fed to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import functools\n",
    "import pdb\n",
    "import traceback\n",
    "\n",
    "\n",
    "# if you want to use as a context manager over certain sections of a function\n",
    "@contextlib.contextmanager\n",
    "def epic_debugger(debug_always=False, enabled=True, do_pdb=True, exception_fn=None, normal_debug_fn=None, **debug_kwargs):\n",
    "    \"\"\"\n",
    "    :param debug_always: whether to run a portion of code regardless of whether an exception is raised\n",
    "    :param enabled: whether to run the debugger at all, so can be easily enabled from an args/config without needing to change code\n",
    "    :param do_pdb: activate pythons debugger if an exception is raised\n",
    "    :param exception_fn: function to run if an exception is raised\n",
    "    :param normal_debug_fn: function to run if no exception is raised\n",
    "    \"\"\"\n",
    "    # default behavior\n",
    "    try:\n",
    "        yield\n",
    "\n",
    "    # if there is an error\n",
    "    except Exception as e:\n",
    "        if enabled:\n",
    "            traceback.print_exc()\n",
    "            if exception_fn is not None:\n",
    "                print(\"*\"*10 + \" BEGIN EXCEPTION_FN \" + \"*\"*10)\n",
    "                exception_fn(**debug_kwargs)\n",
    "                print(\"*\"*10 + \" END EXCEPTION_FN \" + \"*\"*10)\n",
    "            if do_pdb:\n",
    "                pdb.set_trace()\n",
    "        raise e\n",
    "\n",
    "    # if debug_always is enabled\n",
    "    finally:\n",
    "        if debug_always and enabled:\n",
    "            if normal_debug_fn is not None:\n",
    "                print(\"*\"*10 + \" BEGIN DEBUG_FN \" + \"*\"*10)\n",
    "                normal_debug_fn(**debug_kwargs)\n",
    "                print(\"*\"*10 + \" END DEBUG_FN \" + \"*\"*10)\n",
    "\n",
    "\n",
    "\n",
    "# if you want to use as a decorator over an entire function\n",
    "def epic_debugger_decorator(enabled=True, debug_always=False, do_pdb=True, exception_fn=None, normal_debug_fn=None, **debug_kwargs):\n",
    "    \"\"\"\n",
    "    :param enabled: whether to run a portion of code regardless of whether an exception is raised\n",
    "    :param debug_always:  whether to run the debugger at all, so can be easily enabled from an args/config without needing to change code\n",
    "    :param do_pdb: activate pythons debugger if an exception is raised\n",
    "    :param exception_fn: function to run if an exception is raised\n",
    "    :param normal_debug_fn: function to run if no exception is raised\n",
    "    \"\"\"\n",
    "    def debug_decorator(func):\n",
    "        # a wrapper to go around your function\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                # run the actual function\n",
    "                result = func(*args, **kwargs)\n",
    "                # if debug_always is enabled run this portion\n",
    "                if debug_always and enabled:\n",
    "                    if normal_debug_fn is not None:\n",
    "                        print(\"*\"*10 + \" BEGIN DEBUG_FN \" + \"*\"*10)\n",
    "                        normal_debug_fn(**debug_kwargs)\n",
    "                        print(\"*\"*10 + \" END DEBUG_FN \" + \"*\"*10)\n",
    "\n",
    "                # return the output of the original function\n",
    "                return result\n",
    "\n",
    "            # if there is an error\n",
    "            except Exception as e:\n",
    "                if enabled:\n",
    "                    traceback.print_exc()\n",
    "                    if exception_fn is not None:\n",
    "                        print(\"*\"*10 + \" BEGIN EXCEPTION_FN \" + \"*\"*10)\n",
    "                        exception_fn(**debug_kwargs)\n",
    "                        print(\"*\"*10 + \" END EXCEPTION_FN \" + \"*\"*10)\n",
    "                    if do_pdb:\n",
    "                        pdb.set_trace()\n",
    "                # Re-raise the exception after handling\n",
    "                raise e\n",
    "\n",
    "        return wrapper\n",
    "    return debug_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple example\n",
    "def broken_fn(x):\n",
    "    return x / 0\n",
    "\n",
    "with epic_debugger(debug_always=False, enabled=True, do_pdb=True, exception_fn=None, normal_debug_fn=None):\n",
    "    broken_fn(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the decorator\n",
    "@epic_debugger_decorator(debug_always=False, enabled=True, do_pdb=True, exception_fn=None, normal_debug_fn=None)\n",
    "def broken_fn(x):\n",
    "    return x / 0\n",
    "\n",
    "broken_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def another_broken_fn(a_dict, a_list):\n",
    "    return a_dict + a_list\n",
    "\n",
    "def print_named_vars(names=None):\n",
    "    for name, obj in globals().items():\n",
    "        if names is not None:\n",
    "            if name not in names:\n",
    "                continue\n",
    "        print(name, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** BEGIN EXCEPTION_FN **********\n",
      "fruits {'apple': 1, 'banana': 2}\n",
      "numbers [1, 2, 3]\n",
      "********** END EXCEPTION_FN **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_4069491/1114188134.py\", line 19, in epic_debugger\n",
      "    yield\n",
      "  File \"/tmp/ipykernel_4069491/307613978.py\", line 4, in <module>\n",
      "    another_broken_fn(fruits, numbers)\n",
      "  File \"/tmp/ipykernel_4069491/4278361117.py\", line 2, in another_broken_fn\n",
      "    return a_dict + a_list\n",
      "TypeError: unsupported operand type(s) for +: 'dict' and 'list'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m numbers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epic_debugger(debug_always\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, do_pdb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, exception_fn\u001b[38;5;241m=\u001b[39mprint_named_vars, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfruits\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumbers\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43manother_broken_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfruits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumbers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m, in \u001b[0;36manother_broken_fn\u001b[0;34m(a_dict, a_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manother_broken_fn\u001b[39m(a_dict, a_list):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma_list\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'list'"
     ]
    }
   ],
   "source": [
    "fruits = {\"apple\": 1, \"banana\": 2}\n",
    "numbers = [1, 2, 3]\n",
    "with epic_debugger(debug_always=True, do_pdb=False, exception_fn=print_named_vars, names=[\"fruits\", \"numbers\"]):\n",
    "    another_broken_fn(fruits, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# an example of printing out torch tensor details when we fail to add two tensors of different shapes\n",
    "\n",
    "def print_tensor_details(tensor, name=None):\n",
    "    if name is None:\n",
    "        name = \"\"\n",
    "    print(f\"{name} Device: {tensor.device}\")\n",
    "    print(f\"{name} Type: {tensor.dtype}\")\n",
    "    print(f\"{name} Shape: {tensor.shape}\")\n",
    "    print(f\"{name} dtype: {tensor.dtype}\")\n",
    "    print(f\"{name} Is Nan: {torch.isnan(tensor).any()}\")\n",
    "    print(f\"{name} Is Inf: {torch.isinf(tensor).any()}\")\n",
    "    print(f\"{name} Min: {torch.min(tensor)}\")\n",
    "    print(f\"{name} Max: {torch.max(tensor)}\")\n",
    "    if tensor.dtype in [torch.float32, torch.float64, torch.float16, torch.bfloat16]:\n",
    "        print(f\"{name} Mean: {torch.mean(tensor)}\")\n",
    "        print(f\"{name} Std: {torch.std(tensor)}\")\n",
    "    if hasattr(tensor, \"grad\") and tensor.grad is not None:\n",
    "        print_tensor_details(tensor.grad, name=name + \" Grad\" if name else \"Grad\")\n",
    "\n",
    "\n",
    "def print_vars(names=None):\n",
    "    for name, var in globals().items():\n",
    "\n",
    "        # only perform debugging for specific variables if we provide that\n",
    "        if names is not None:\n",
    "            if name not in names:\n",
    "                continue\n",
    "\n",
    "        # if a tensor, print details\n",
    "        if isinstance(var, torch.Tensor):\n",
    "            print_tensor_details(var, name=name)\n",
    "            print(\"---\"*5)\n",
    "\n",
    "        # if dictionary, tuple, or list, print a map of its hiearchy\n",
    "        elif isinstance(var, (dict, tuple, list)):\n",
    "            analyze_hierarchy(var, name)\n",
    "            print(\"---\"*5)\n",
    "\n",
    "\n",
    "def recursive(obj, string_to_print, depth, keyname=None):\n",
    "    string = f\"{depth * '- '}\"\n",
    "    if keyname is not None:\n",
    "        string += f\"{keyname}\"\n",
    "    string += f\" {type(obj)}\"\n",
    "\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        string_to_print += [f\"{string}, length:{len(obj)}\"]\n",
    "        for item in obj:\n",
    "            string_to_print = recursive(item, string_to_print, depth + 1)\n",
    "\n",
    "    elif isinstance(obj, dict):\n",
    "        string_to_print += [f\"{string}, length:{len(obj)}\"]\n",
    "        for key, value in obj.items():\n",
    "            string_to_print = recursive(value, string_to_print, depth + 1, keyname=key)\n",
    "\n",
    "    else:\n",
    "        string_to_print += [f\"{string}\"]\n",
    "\n",
    "    return string_to_print\n",
    "\n",
    "\n",
    "def analyze_hierarchy(obj, name):\n",
    "    \"\"\"\n",
    "    decomposes a dictionary, list, or tuple into its components and prints attributes\n",
    "    \"\"\"\n",
    "    string_to_print = []\n",
    "    depth = 0\n",
    "    string_to_print = recursive(obj, string_to_print, depth, keyname=name)\n",
    "    string_to_print = \"\\n\".join(string_to_print)\n",
    "    print(string_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = {\"a\": 1, \"b\": 2, \"c\": [1, 2, 3], \"d\": {\"e\": 1, \"f\": 2, \"g\": [(4,5,6), 2, 3]}}\n",
    "tensor1 = torch.arange(4)\n",
    "tensor2 = torch.arange(5)\n",
    "\n",
    "def broken_fn(dictionary, a, b):\n",
    "    print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** BEGIN EXCEPTION_FN **********\n",
      "thing <class 'dict'>, length:4\n",
      "- a <class 'int'>\n",
      "- b <class 'int'>\n",
      "- c <class 'list'>, length:3\n",
      "- -  <class 'int'>\n",
      "- -  <class 'int'>\n",
      "- -  <class 'int'>\n",
      "- d <class 'dict'>, length:3\n",
      "- - e <class 'int'>\n",
      "- - f <class 'int'>\n",
      "- - g <class 'list'>, length:3\n",
      "- - -  <class 'tuple'>, length:3\n",
      "- - - -  <class 'int'>\n",
      "- - - -  <class 'int'>\n",
      "- - - -  <class 'int'>\n",
      "- - -  <class 'int'>\n",
      "- - -  <class 'int'>\n",
      "---------------\n",
      "tensor1 Device: cpu\n",
      "tensor1 Type: torch.int64\n",
      "tensor1 Shape: torch.Size([4])\n",
      "tensor1 dtype: torch.int64\n",
      "tensor1 Is Nan: False\n",
      "tensor1 Is Inf: False\n",
      "tensor1 Min: 0\n",
      "tensor1 Max: 3\n",
      "---------------\n",
      "tensor2 Device: cpu\n",
      "tensor2 Type: torch.int64\n",
      "tensor2 Shape: torch.Size([5])\n",
      "tensor2 dtype: torch.int64\n",
      "tensor2 Is Nan: False\n",
      "tensor2 Is Inf: False\n",
      "tensor2 Min: 0\n",
      "tensor2 Max: 4\n",
      "---------------\n",
      "********** END EXCEPTION_FN **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_4069491/1114188134.py\", line 19, in epic_debugger\n",
      "    yield\n",
      "  File \"/tmp/ipykernel_4069491/4073057097.py\", line 2, in <module>\n",
      "    broken_fn(thing, tensor1, tensor2)\n",
      "  File \"/tmp/ipykernel_4069491/3653530737.py\", line 6, in broken_fn\n",
      "    print(a + b)\n",
      "RuntimeError: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epic_debugger(debug_always\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, do_pdb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, exception_fn\u001b[38;5;241m=\u001b[39mprint_vars, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthing\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor2\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mbroken_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[140], line 6\u001b[0m, in \u001b[0;36mbroken_fn\u001b[0;34m(dictionary, a, b)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroken_fn\u001b[39m(dictionary, a, b):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "with epic_debugger(debug_always=True, do_pdb=False, exception_fn=print_vars, names=[\"thing\", \"tensor1\", \"tensor2\"]):\n",
    "    broken_fn(thing, tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a function that actually works, but may hide silent errors if tensor values are not checked\n",
    "tensor1 = torch.arange(4) / 0\n",
    "tensor2 = torch.arange(4)\n",
    "\n",
    "def add_tensors(a,b):\n",
    "    return a + b\n",
    "    \n",
    "# runs no problem\n",
    "out = add_tensors(tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this case, because no exception happens, we'll want to use normal_debug_fn and always_debug=True\n",
    "def throw_if_nan():\n",
    "    for name, var in globals().items():\n",
    "        # if a tensor, print details\n",
    "        if isinstance(var, torch.Tensor):\n",
    "            if torch.isnan(var).any():\n",
    "                print(f\"NaN found in {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** BEGIN DEBUG_FN **********\n",
      "NaN found in tensor1\n",
      "NaN found in out\n",
      "********** END DEBUG_FN **********\n"
     ]
    }
   ],
   "source": [
    "@epic_debugger(debug_always=True, do_pdb=False, normal_debug_fn=throw_if_nan)\n",
    "def add_tensors(a,b):\n",
    "    return a + b\n",
    "\n",
    "out = add_tensors(tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
